{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = yelp_api_key\n",
    "base_url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "cities = [\"Manhattan\", \"Queens\", \"Brooklyn\", \"Bronx\", \"Staten Island\"]\n",
    "results_per_page = 20  # Number of results per API request\n",
    "all_eats_data = []\n",
    "for city in cities:\n",
    "    offset = 0  # Start with 0 offset\n",
    "    while True:\n",
    "        params = {\n",
    "            \"term\": \"restaurants\",\n",
    "            \"location\": city,\n",
    "            \"offset\": offset,  # Offset for pagination\n",
    "            \"limit\": results_per_page  # Number of results per page\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        eats_data = response.json()\n",
    "        # Process the data as needed\n",
    "        businesses = eats_data.get(\"businesses\", [])\n",
    "        if not businesses:\n",
    "            break  # No more businesses, exit the loop\n",
    "        for business in businesses:\n",
    "            data = {\n",
    "                \"City\": city,\n",
    "                \"Name\": business[\"name\"],\n",
    "                \"Address\": business[\"location\"][\"address1\"]\n",
    "            }\n",
    "            all_eats_data.append(data)\n",
    "        offset += results_per_page  # Increment offset for the next page\n",
    "# Create a DataFrame from the collected data\n",
    "eats_data_df = pd.DataFrame(all_eats_data)\n",
    "# Save the DataFrame to a CSV file\n",
    "eats_data_df.to_csv(\"nyc_eats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
